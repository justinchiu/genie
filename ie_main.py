# VAL NUMBERS

# UNSUP TEXT GEN

# Summary level

## Soft has values
# Hard model q (summary level)
# acc: 0.722 | E acc: 0.761 | T acc: 0.854
# python ie_main.py --devid 3 --model crnnlmca --dp 0 --bsz 128 --eval-only ie-d-crnnlmca-elbo-es256-rs256-b6-lr0.001-lrd0.1-dp0.0-twTrue-ifFalse-saFalse-K8-ks10000-scFalse-qqay-nvFalse-jcTrue/ie-d-crnnlmca-elbo-es256-rs256-b6-lr0.001-lrd0.1-dp0.0-twTrue-ifFalse-saFalse-K8-ks10000-scFalse-qqay-nvFalse-jcTrue-e26.pt
 
# Hard model for numerical values q (summary level)
# acc: 0.658 | E acc: 0.725 | T acc: 0.739
# python ie_main.py --devid 3 --model crnnlmca --dp 0 --bsz 128 --numericvalues --eval-only ie-d-crnnlmca-elbo-es256-rs256-b6-lr0.001-lrd0.1-dp0.0-twTrue-ifFalse-saFalse-K8-ks10000-scFalse-qqay-nvFalse-jcTrue/ie-d-crnnlmca-elbo-es256-rs256-b6-lr0.001-lrd0.1-dp0.0-twTrue-ifFalse-saFalse-K8-ks10000-scFalse-qqay-nvFalse-jcTrue-e26.pt
 
# Hard model p (summary level)
# acc: 0.508 | E acc: 0.567 | T acc: 0.746
# python ie_main.py --devid 3 --model crnnlmca --dp 0 --bsz 128 --evalp --eval-only ie-d-crnnlmca-elbo-es256-rs256-b6-lr0.001-lrd0.1-dp0.0-twTrue-ifFalse-saFalse-K8-ks10000-scFalse-qqay-nvFalse-jcTrue/ie-d-crnnlmca-elbo-es256-rs256-b6-lr0.001-lrd0.1-dp0.0-twTrue-ifFalse-saFalse-K8-ks10000-scFalse-qqay-nvFalse-jcTrue-e26.pt
 
# Hard model for numerical values p (summary level)
# acc: 0.640 | E acc: 0.716 | T acc: 0.722
# python ie_main.py --devid 3 --model crnnlmca --dp 0 --bsz 128 --numericvalues --evalp --eval-only ie-d-crnnlmca-elbo-es256-rs256-b6-lr0.001-lrd0.1-dp0.0-twTrue-ifFalse-saFalse-K8-ks10000-scFalse-qqay-nvFalse-jcTrue/ie-d-crnnlmca-elbo-es256-rs256-b6-lr0.001-lrd0.1-dp0.0-twTrue-ifFalse-saFalse-K8-ks10000-scFalse-qqay-nvFalse-jcTrue-e26.pt

# Soft no values
# Hard model q (summary level)
# acc: 0.6746685775707632 | E acc: 0.733043022903288 | T acc: 0.851087286056831
# python ie_main.py --devid 3 --model crnnlmca --dp 0 --bsz 128 --eval-only ie-d-crnnlmca-elbo-es256-rs256-b6-lr0.001-lrd0.1-dp0.0-twTrue-ifFalse-saFalse-K8-ks10000-scFalse-qqay-nvTrue-jcTrue-tfFalse-qcTrue-qrTrue/ie-d-crnnlmca-elbo-es256-rs256-b6-lr0.001-lrd0.1-dp0.0-twTrue-ifFalse-saFalse-K8-ks10000-scFalse-qqay-nvTrue-jcTrue-tfFalse-qcTrue-qrTrue-e26.pt
 
# Hard model for numerical values q (summary level)
# acc: 0.6071366606905326 | E acc: 0.6967786709849054 | T acc: 0.756173731999306
# python ie_main.py --devid 3 --model crnnlmca --dp 0 --bsz 128 --numericvalues --eval-only ie-d-crnnlmca-elbo-es256-rs256-b6-lr0.001-lrd0.1-dp0.0-twTrue-ifFalse-saFalse-K8-ks10000-scFalse-qqay-nvTrue-jcTrue-tfFalse-qcTrue-qrTrue/ie-d-crnnlmca-elbo-es256-rs256-b6-lr0.001-lrd0.1-dp0.0-twTrue-ifFalse-saFalse-K8-ks10000-scFalse-qqay-nvTrue-jcTrue-tfFalse-qcTrue-qrTrue-e26.pt
 
# Hard model p (summary level)
# acc: 0.4510376760466334 | E acc: 0.5257834247443707 | T acc: 0.7716010252735441
# python ie_main.py --devid 3 --model crnnlmca --dp 0 --bsz 128 --evalp --eval-only ie-d-crnnlmca-elbo-es256-rs256-b6-lr0.001-lrd0.1-dp0.0-twTrue-ifFalse-saFalse-K8-ks10000-scFalse-qqay-nvTrue-jcTrue-tfFalse-qcTrue-qrTrue/ie-d-crnnlmca-elbo-es256-rs256-b6-lr0.001-lrd0.1-dp0.0-twTrue-ifFalse-saFalse-K8-ks10000-scFalse-qqay-nvTrue-jcTrue-tfFalse-qcTrue-qrTrue-e26.pt
 
# Hard model for numerical values p (summary level)
# acc: 0.5421317448383552 | E acc: 0.6417789601526805 | T acc: 0.7320571395523683
# python ie_main.py --devid 3 --model crnnlmca --dp 0 --bsz 128 --numericvalues --evalp --eval-only ie-d-crnnlmca-elbo-es256-rs256-b6-lr0.001-lrd0.1-dp0.0-twTrue-ifFalse-saFalse-K8-ks10000-scFalse-qqay-nvTrue-jcTrue-tfFalse-qcTrue-qrTrue/ie-d-crnnlmca-elbo-es256-rs256-b6-lr0.001-lrd0.1-dp0.0-twTrue-ifFalse-saFalse-K8-ks10000-scFalse-qqay-nvTrue-jcTrue-tfFalse-qcTrue-qrTrue-e26.pt


# Hard model q (crnnlmqca) (summary level)
# acc: 0.6051318799437754 | E acc: 0.6268224788468428 | T acc: 0.7097263181104099
# python ie_main.py --devid 2 --model crnnlmqca --dp 0 --bsz 128 --eval-only ie-crnnlmqca-elbo-es256-rs256-b6-lr0.001-lrd0.1-dp0.0-twTrue-ifFalse-saFalse-K8-ks0-scFalse-qqay-nvFalse-jcTrue-tfFalse-qcFalse-qrFalse/ie-crnnlmqca-elbo-es256-rs256-b6-lr0.001-lrd0.1-dp0.0-twTrue-ifFalse-saFalse-K8-ks0-scFalse-qqay-nvFalse-jcTrue-tfFalse-qcFalse-qrFalse-e22.pt

# Hard model p (crnnlmqca) (summary level)
# acc: 0.4046798776286415 | E acc: 0.4627511506766254 | T acc: 0.6018521070473776
# python ie_main.py --devid 2 --model crnnlmqca --dp 0 --bsz 128 --evalp --eval-only ie-crnnlmqca-elbo-es256-rs256-b6-lr0.001-lrd0.1-dp0.0-twTrue-ifFalse-saFalse-K8-ks0-scFalse-qqay-nvFalse-jcTrue-tfFalse-qcFalse-qrFalse/ie-crnnlmqca-elbo-es256-rs256-b6-lr0.001-lrd0.1-dp0.0-twTrue-ifFalse-saFalse-K8-ks0-scFalse-qqay-nvFalse-jcTrue-tfFalse-qcFalse-qrFalse-e22.pt



# Soft attention numbers (summary level)
# acc: 0.288| E acc: 0.364 | T acc: 0.358
# python ie_main.py --model crnnlma --devid 2 --lr 0.001 --dp 0 --bsz 128 --re 10 --lrd 0.5 --attn rnn --eval-only ie-d-crnnlma-elbo-es256-rs256-b6-lr0.001-lrd0.1-dp0.0-twTrue-ifFalse-saFalse-K1-ks0-scFalse-qqay/ie-d-crnnlma-elbo-es256-rs256-b6-lr0.001-lrd0.1-dp0.0-twTrue-ifFalse-saFalse-K1-ks0-scFalse-qqay-e22.pt
 
# Soft attention numbers for numeric values (summary level)
# acc: 0.514 | E acc: 0.578 | T acc: 0.591
# python ie_main.py --model crnnlma --devid 2 --dp 0 --bsz 128 --numericvalues --eval-only ie-d-crnnlma-elbo-es256-rs256-b6-lr0.001-lrd0.1-dp0.0-twTrue-ifFalse-saFalse-K1-ks0-scFalse-qqay/ie-d-crnnlma-elbo-es256-rs256-b6-lr0.001-lrd0.1-dp0.0-twTrue-ifFalse-saFalse-K1-ks0-scFalse-qqay-e22.pt

# HEURISTIC SUPERVISED

# Sentence level

# Emb attn blstm rnnie numbers
# acc: 0.855 | E acc: 0.872 | T acc: 0.952
# python ie_main.py --devid 0 --lr 0.001 --dp 0 --bsz 128 --sentences --re 10 --model rnnaie --attn emb
 
# Rnn attn blstm rnnie numbers
# acc: 0.865 | E acc: 0.880 | T acc: 0.956
# python ie_main.py --devid 0 --lr 0.001 --dp 0 --bsz 128 --sentences --re 10 --model rnnaie --attn rnn
 
# Blstm rnnie numbers
# acc: 0.852 | E acc: 0.872 | T acc: 0.949
# python ie_main.py --devid 0 --lr 0.01 --dp 0.3 --bsz 128 --sentences --re 10 --lrd 0.5
 
# Blstm rnnie numbers for numeric values
# acc: 0.752 | E acc: 0.776 | T acc: 0.919
# python ie_main.py --devid 0 --lr 0.01 --dp 0.3 --bsz 128 --sentences --re 10 --lrd 0.5 --numericvalues


# Summary level

# Blstm rnnie numbers
# acc: 0.908 | E acc: 0.924 | T acc: 0.961
# python ie_main.py --devid 0 --lr 0.001 --dp 0 --bsz 128 --re 10 --model rnnie
 
# Rnn attn blstm rnnie numbers
# acc: 0.| E acc: 0.| T acc: 0.
# python ie_main.py --devid 0 --lr 0.001 --dp 0 --bsz 128 --re 10 --model rnnaie --attn rnn
 
# Blstm rnnie numbers
# acc: 0.| E acc: 0.| T acc: 0.
# python ie_main.py --devid 0 --lr 0.01 --dp 0.3 --bsz 128 --re 10 --lrd 0.5
 
# Blstm rnnie numbers for numeric values
# acc: 0.811 || E acc: 0.842 || T acc: 0.922
# python ie_main.py --devid 0 --lr 0.01 --dp 0.3 --bsz 128 --re 10 --lrd 0.5 --numericvalues


# Full IE, vie numbers
# Blstm rnnvie (sentence)
# acc: 0.350 || copyable: 0.031026840796604803
# python ie_main.py --devid 0 --lr 0.01 --dp 0.3 --bsz 128 --re 10 --lrd 0.5 --sentences

# Blstm rnnvie (summary)
# acc: 0.322 || copyable: 0.41552589846004245
# python ie_main.py --devid 0 --lr 0.01 --dp 0.3 --bsz 128 --re 10 --lrd 0.5



# Newer correcter results
# crnnlmqca K=64
# acc: 0.7516192156106165 | E acc: 0.776479342942976 | T acc: 0.8729156905437808
# (ntensor) [jchiu@sum1gpu03 rotowIrE]$ python ie_main.py --devid 2 --model crnnlmca --dp 0 --bsz 128 -
# -eval-only fuck2
# -crnnlmqca-elbo-es256-rs256-b6-lr0.001-lrd0.1-dp0.0-twTrue-ifFalse-saFalse-K64-ks0-scFalse-qqay-nvFal
# se-jcTrue-tfFals
# e-qcFalse-qrFalse-t1/fuck2-crnnlmqca-elbo-es256-rs256-b6-lr0.001-lrd0.1-dp0.0-twTrue-ifFalse-saFalse-
# K64-ks0-scFalse-
# qqay-nvFalse-jcTrue-tfFalse-qcFalse-qrFalse-t1-e19.pt
# 
# 
# crnnlmqca numericvalues K=64
# acc: 0.630385749812041 | E acc: 0.6745705858539124 | T acc: 0.7543808917934185
# (ntensor) [jchiu@sum1gpu03 rotowIrE]$ python ie_main.py --devid 2 --model crnnlmca --dp 0 --bsz 128 -
# -eval-only fuck2-crnnlmqca-elbo-es256-rs256-b6-lr0.001-lrd0.1-dp0.0-twTrue-ifFalse-saFalse-K64-ks0-sc
# False-qqay-nvFalse-jcTrue-tfFalse-qcFalse-qrFalse-t1/fuck2-crnnlmqca-elbo-es256-rs256-b6-lr0.001-lrd0
# .1-dp0.0-twTrue-ifFalse-saFalse-K64-ks0-scFalse-qqay-nvFalse-jcTrue-tfFalse-qcFalse-qrFalse-t1-e19.pt
#  --numericvalues
#
# crnnlmqca evalp K=64
# acc: 0.5159165449384009 | E acc: 0.5588567648761128 | T acc: 0.7725932254774963
# (ntensor) [jchiu@sum1gpu03 rotowIrE]$ python ie_main.py --devid 2 --model crnnlmca --dp 0 --bsz 128 -
# -eval-only fuck2-crnnlmqca-elbo-es256-rs256-b6-lr0.001-lrd0.1-dp0.0-twTrue-ifFalse-saFalse-K64-ks0-sc
# False-qqay-nvFalse-jcTrue-tfFalse-qcFalse-qrFalse-t1/fuck2-crnnlmqca-elbo-es256-rs256-b6-lr0.001-lrd0
# .1-dp0.0-twTrue-ifFalse-saFalse-K64-ks0-scFalse-qqay-nvFalse-jcTrue-tfFalse-qcFalse-qrFalse-t1-e19.pt
# --evalp
#
# 
# crnnlmqca numericalvalues evalp K=64
# acc: 0.5901914290671447 | E acc: 0.658030189115725 | T acc: 0.6787346018159737
# python ie_main.py --devid 2 --model crnnlmqca --dp 0 --bsz 128
# --eval-only fuck2-crnnlmqca-elbo-es256-rs256-b6-lr0.001-lrd0.1-dp0.0-twTrue-ifFalse-saFalse-K64-ks0-sc
# False-qqay-nvFalse-jcTrue-tfFalse-qcFalse-qrFalse-t1/fuck2-crnnlmqca-elbo-es256-rs256-b6-lr0.001-lrd0
# .1-dp0.0-twTrue-ifFalse-saFalse-K64-ks0-scFalse-qqay-nvFalse-jcTrue-tfFalse-qcFalse-qrFalse-t1-e19.pt
# --numericvalues --evalp

# Blstm rnnie (summary), P@1
# acc: 0.8718408069894992 | E acc: 0.89482677838106 | T acc: 0.9492875451313287
# (ntensor) [jchiu@sum1gpu03 rotowIrE]$ python ie_main.py --devid 3 --lr 0.001 --dp 0 --bsz 128 --re 10
# --model rnnie --save --reset
# 
import argparse
import random
import json
import sys
import os
import pathlib


import torch
import torch.optim as optim

import data
from data import RotoExample
import nytdata
from nytdata import NytExample

from models.rnnie import RnnIe
from models.rnnaie import RnnAie
from models.rnnvie import RnnVie

from models.crnnlma import CrnnLmA
from models.crnnlmsa import CrnnLmSa
from models.crnnlmca import CrnnLmCa
from models.crnnlmqca import CrnnLmQca
from models.crnnlmeqca import CrnnLmEqca
from models.crnnlmesqca import CrnnLmEsqca
from models.crnnlmcqca import CrnnLmCqca
from models.crnnlmecqca import CrnnLmEcqca

#torch.backends.cudnn.enabled = False
torch.backends.cudnn.enabled = True
torch.backends.cudnn.deterministic = True

# debug
#torch.autograd.set_detect_anomaly(True)

def get_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        "--filepath",
        default="rotowire",
        # "nyt/nyt10"
        type=str,
    )

    parser.add_argument(
        "--dataset",
        choices=[
            "rotowire",
            "nyt",
        ],
        default="rotowire",
    )

    parser.add_argument("--devid", default=-1, type=int)

    parser.add_argument("--bsz", default=32, type=int)
    parser.add_argument("--epochs", default=32, type=int)
    parser.add_argument("--exactepochs", default=4, type=int)

    parser.add_argument("--minfreq", default=1, type=int)

    parser.add_argument("--clip", default=5, type=float)
    parser.add_argument("--lr", default=0.01, type=float)
    parser.add_argument("--lrd", default=0.1, type=float)
    parser.add_argument("--pat", default=0, type=int)
    parser.add_argument("--dp", default=0.3, type=float)
    parser.add_argument("--wdp", default=0, type=float)
    parser.add_argument("--wd", default=1e-4, type=float)

    parser.add_argument("--klannealsteps", default=120000, type=int)

    parser.add_argument("--maxlen", default=-1, type=int)
    parser.add_argument("--sentences", action="store_true")
    parser.add_argument("--reset", action="store_true")
    parser.add_argument("--numericvalues", action="store_true")
    parser.add_argument("--vie", action="store_true", help="Full slot filling task")

    parser.add_argument("--T", default=64, type=int, help="Time split")
    parser.add_argument("--E", default=32, type=int, help="Entity split")
    parser.add_argument("--R", default=4, type=int, help="Relation (type) split")
    parser.add_argument("--K", default=1, type=int)
    parser.add_argument("--mode", choices=["elbo", "marginal", "iwae"], default="elbo")
    parser.add_argument("--q", choices=["pa", "qay", "pay"], default="qay")

    parser.add_argument("--optim", choices=["Adam", "SGD"])

    # Adam
    parser.add_argument("--b1", type=float, default=0.9)
    parser.add_argument("--b2", type=float, default=0.999)
    parser.add_argument("--eps", type=float, default=1e-8)

    # SGD
    parser.add_argument("--mom", type=float, default=0)
    parser.add_argument("--dm", type=float, default=0)
    parser.add_argument("--nonag", action="store_true", default=False)

    # Model
    parser.add_argument(
        "--model",
        choices=[
            "rnnie",
            "rnnaie",
            "crnnlma",
            "rnnvie",
            "crnnlmca",
            "crnnlmsa",
            "crnnlmqca",
            "crnnlmeqca",
            "crnnlmcqca",
            "crnnlmecqca",
        ],
        default="rnnie"
    )

    parser.add_argument("--attn", choices=["emb", "rnn"], default="emb")
    parser.add_argument("--joint", action="store_true")

    parser.add_argument("--nlayers", default=2, type=int)
    parser.add_argument("--emb-sz", default=256, type=int)
    parser.add_argument("--rnn-sz", default=256, type=int)
    parser.add_argument("--tieweights", action="store_true")

    parser.add_argument("--inputfeed", action="store_true")
    parser.add_argument("--supattn", action="store_true")
    parser.add_argument("--supcopy", action="store_true")
    parser.add_argument("--evalp", action="store_true")

    parser.add_argument("--save", action="store_true")
    parser.add_argument("--eval-only", type=str, default=None)

    parser.add_argument("--re", default=100, type=int)

    parser.add_argument("--seed", default=1111, type=int)
    parser.add_argument("--old-model", action="store_true")
    parser.add_argument("--prefix", type=str, default="")
    return parser.parse_args()


args = get_args()
print(args)
modelname = f"{args.prefix}-{args.dataset}-{args.model}-s{args.sentences}-rs{args.rnn_sz}-b{args.bsz}-lr{args.lr}-lrd{args.lrd}-dp{args.dp}-a{args.attn}"
if args.maxlen > 0:
    modelname = f"dbg-model-maxlen{args.maxlen}"
pathlib.Path(modelname).mkdir(parents=True, exist_ok=True)

if args.old_model:
    from models.crnnmlmc_old import CrnnMlmC
else:
    from models.crnnmlmc import CrnnMlmC

random.seed(args.seed)
torch.manual_seed(args.seed)
torch.cuda.manual_seed(args.seed)

device = torch.device(f"cuda:{args.devid}" if args.devid >= 0 else "cpu")

# Data
dataset = data.RotoDataset if args.dataset == "rotowire" else nytdata.NytDataset
ENT, TYPE, VALUE, VALUE_TEXT, TEXT = data.make_fields(args.maxlen + 1)
train, valid, test = dataset.splits(
    ENT, TYPE, VALUE, VALUE_TEXT, TEXT,
    path = args.filepath,
    sentences = args.sentences,
    reset = args.reset,
    numericvalues = args.numericvalues,
)

data.build_vocab(ENT, TYPE, VALUE, TEXT, train, min_freq=args.minfreq)
# is this enough?
TEXT.vocab.extend(VALUE.vocab)
VALUE_TEXT.vocab = TEXT.vocab

iterator = data.RotowireIterator if args.dataset == "rotowire" else nytdata.NytIterator
train_iter, valid_iter, test_iter = iterator.splits(
    (train, valid, test),
    batch_size = args.bsz,
    device = device,
    repeat = False,
    sort_within_batch = True,
    #sort_key = already given in dataset?
)

model_state = None
if args.eval_only:
    eval_args = args
    thing = torch.load(args.eval_only, map_location="cpu")
    model_state, args = thing["model"], thing["args"]
    args.eval_only = True
    # Use new T and E
    args.T = eval_args.T
    args.E = eval_args.E
    args.evalp = eval_args.evalp
    print("eval args:")
    print(args)


# Model
if args.model == "rnnie":
    model = RnnIe(
        Ve = ENT.vocab,
        Vt = TYPE.vocab,
        Vv = VALUE.vocab,
        Vx = TEXT.vocab,
        x_emb_sz = args.emb_sz,
        rnn_sz = args.rnn_sz,
        nlayers = args.nlayers,
        dropout = args.dp,
        joint   = args.joint,
    )
elif args.model == "rnnaie":
    model = RnnAie(
        Ve = ENT.vocab,
        Vt = TYPE.vocab,
        Vv = VALUE.vocab,
        Vx = TEXT.vocab,
        x_emb_sz = args.emb_sz,
        rnn_sz = args.rnn_sz,
        nlayers = args.nlayers,
        dropout = args.dp,
        attn    = args.attn,
        joint   = args.joint,
    )
elif args.model == "crnnlma":
    model = CrnnLmA(
        Ve = ENT.vocab,
        Vt = TYPE.vocab,
        Vv = VALUE.vocab,
        Vx = TEXT.vocab,
        r_emb_sz = args.emb_sz,
        x_emb_sz = args.emb_sz,
        rnn_sz = args.rnn_sz,
        nlayers = args.nlayers,
        dropout = args.dp,
        tieweights = args.tieweights,
        inputfeed = args.inputfeed,
    )
elif args.model == "crnnlmsa":
    model = CrnnLmSa(
        Ve = ENT.vocab,
        Vt = TYPE.vocab,
        Vv = VALUE.vocab,
        Vx = TEXT.vocab,
        r_emb_sz = args.emb_sz,
        x_emb_sz = args.emb_sz,
        rnn_sz = args.rnn_sz,
        nlayers = args.nlayers,
        dropout = args.dp,
        tieweights = args.tieweights,
        inputfeed = args.inputfeed,
        noattnvalues = args.noattnvalues,
        initu = args.initu,
        initg = args.initg,
        v2d = args.v2d,
        initvy = args.initvy,
        mlp = args.mlp,
        hardc = args.hardc,
        fixedc = args.fixedc,
        maskedc = args.maskedc,
    )
elif args.model == "rnnvie":
    model = RnnVie(
        Ve = ENT.vocab,
        Vt = TYPE.vocab,
        Vv = VALUE.vocab,
        Vx = TEXT.vocab,
        x_emb_sz = args.emb_sz,
        r_emb_sz = args.emb_sz,
        rnn_sz = args.rnn_sz,
        nlayers = args.nlayers,
        dropout = args.dp,
        attn    = args.attn,
        joint   = args.joint,
    )
elif args.model == "crnnlmca":
    model = CrnnLmCa(
        Ve = ENT.vocab,
        Vt = TYPE.vocab,
        Vv = VALUE.vocab,
        Vx = TEXT.vocab,
        r_emb_sz = args.emb_sz,
        x_emb_sz = args.emb_sz,
        rnn_sz = args.rnn_sz,
        nlayers = args.nlayers,
        dropout = args.dp,
        tieweights = args.tieweights,
        inputfeed = args.inputfeed,
        noattnvalues = args.noattnvalues,
        jointcopy = args.jointcopy,
        qc = args.qc if hasattr(args, "qc") else False,
        qcrnn = args.qcrnn if hasattr(args, "qcrnn") else False,
    )
elif args.model == "crnnlmqca":
    model = CrnnLmQca(
        Ve = ENT.vocab,
        Vt = TYPE.vocab,
        Vv = VALUE.vocab,
        Vx = TEXT.vocab,
        r_emb_sz = args.emb_sz,
        x_emb_sz = args.emb_sz,
        rnn_sz = args.rnn_sz,
        nlayers = args.nlayers,
        dropout = args.dp,
        tieweights = args.tieweights,
        inputfeed = args.inputfeed,
        noattnvalues = args.noattnvalues,
        jointcopy = args.jointcopy,
        qc = args.qc if hasattr(args, "qc") else False,
        qcrnn = args.qcrnn if hasattr(args, "qcrnn") else False,
        v2d = args.v2d if hasattr(args, "v2d") else False
    )
elif args.model == "crnnlmeqca":
    model = CrnnLmEqca(
        Ve = ENT.vocab,
        Vt = TYPE.vocab,
        Vv = VALUE.vocab,
        Vx = TEXT.vocab,
        r_emb_sz = args.emb_sz,
        x_emb_sz = args.emb_sz,
        rnn_sz = args.rnn_sz,
        nlayers = args.nlayers,
        dropout = args.dp,
        tieweights = args.tieweights,
        inputfeed = args.inputfeed,
        noattnvalues = args.noattnvalues,
        jointcopy = args.jointcopy,
        qc = args.qc,
        qcrnn = args.qcrnn,
        temp = args.temp,
        qconly = args.qconly,
        v2d = args.v2d,
        initvy = args.initvy,
        glove = args.glove,
        nuisance = args.nuisance,
        initu = args.initu,
        tanh = args.tanh,
        vctxt = args.vctxt if hasattr(args, "vctxt") else False,
        wcv = args.wcv if hasattr(args, "wcv") else False,
        etvctxt = args.etvctxt if hasattr(args, "etvctxt") else False,
        bil = args.bil if hasattr(args, "bil") else False,
    )
elif args.model == "crnnlmecqca":
    model = CrnnLmEcqca(
        Ve = ENT.vocab,
        Vt = TYPE.vocab,
        Vv = VALUE.vocab,
        Vx = TEXT.vocab,
        r_emb_sz = args.emb_sz,
        x_emb_sz = args.emb_sz,
        rnn_sz = args.rnn_sz,
        nlayers = args.nlayers,
        dropout = args.dp,
        tieweights = args.tieweights,
        inputfeed = args.inputfeed,
        noattnvalues = args.noattnvalues,
        jointcopy = args.jointcopy,
        qc = args.qc,
        qcrnn = args.qcrnn,
        temp = args.temp,
        qconly = args.qconly,
        v2d = args.v2d,
        initvy = args.initvy,
        glove = args.glove,
        nuisance = args.nuisance,
        initu = args.initu,
        tanh = args.tanh,
        vctxt = args.vctxt,
        wcv = args.wcv,
        etvctxt = args.etvctxt,
        bil = args.bil,
        mlp = args.mlp,
        untie = args.untie,
    )
elif args.model == "crnnlmesqca":
    model = CrnnLmEsqca(
        Ve = ENT.vocab,
        Vt = TYPE.vocab,
        Vv = VALUE.vocab,
        Vx = TEXT.vocab,
        r_emb_sz = args.emb_sz,
        x_emb_sz = args.emb_sz,
        rnn_sz = args.rnn_sz,
        nlayers = args.nlayers,
        dropout = args.dp,
        tieweights = args.tieweights,
        inputfeed = args.inputfeed,
        noattnvalues = args.noattnvalues,
        jointcopy = args.jointcopy,
        qc = args.qc,
        qcrnn = args.qcrnn,
        temp = args.temp,
        qconly = args.qconly,
        v2d = args.v2d,
        initvy = args.initvy,
        glove = args.glove,
        nuisance = args.nuisance,
        initu = args.initu,
        tanh = args.tanh,
        vctxt = args.vctxt,
        wcv = args.wcv,
        etvctxt = args.etvctxt,
        bil = args.bil,
    )
elif args.model == "crnnlmcqca":
    model = CrnnLmCqca(
        Ve = ENT.vocab,
        Vt = TYPE.vocab,
        Vv = VALUE.vocab,
        Vx = TEXT.vocab,
        r_emb_sz = args.emb_sz,
        x_emb_sz = args.emb_sz,
        rnn_sz = args.rnn_sz,
        nlayers = args.nlayers,
        dropout = args.dp,
        tieweights = args.tieweights,
        inputfeed = args.inputfeed,
        noattnvalues = args.noattnvalues,
        jointcopy = args.jointcopy,
        qc = args.qc if hasattr(args, "qc") else False,
        qcrnn = args.qcrnn if hasattr(args, "qcrnn") else False,
        v2d = args.v2d if hasattr(args, "v2d") else False,
        nuisance = args.nuisance if hasattr(args, "nuisance") else False,
    )

model.to(device)
print(model)

if args.klannealsteps > 0:
    model.kl_anneal_steps = args.klannealsteps

model.evalp = args.evalp

model.K = 2
model.Ke = 0
model.mode = args.mode
model.q = args.q

model.tao = 1
model.qtao = 1

#dbg
model.ENT = ENT.vocab
model.TYPE = TYPE.vocab
model.VALUE = VALUE.vocab
model.TEXT = TEXT.vocab

if args.eval_only:
    model.load_state_dict(model_state, strict=False)
    #train_loss, ntok, tp, fp, fn, tm, tg = model.validate_ie(train_iter, T=args.T, E=args.E, R=args.R)
    #train_loss, ntok = model.validate_ie(train_iter, T=args.T, E=args.E, R=args.R)
    #print(f"train loss: {train_loss / ntok}")
    #valid_loss, ntok, tp, fp, fn, tm, tg = model.validate_ie(valid_iter, T=args.T, E=args.E, R=args.R)
    valid_loss, ntok = model.validate_ie(valid_iter, T=args.T, E=args.E, R=args.R)
    print(f"valid loss: {valid_loss / ntok}")
    sys.exit(0)

params = list(model.parameters())

optimizer = optim.Adam(
    params, lr = args.lr, weight_decay = args.wd, betas=(args.b1, args.b2))
schedule = optim.lr_scheduler.ReduceLROnPlateau(
    optimizer, patience=args.pat, factor=args.lrd, threshold=1e-3)
#batch = next(iter(train_iter))
# TODO: try truncating sequences early on?

best_val = float("inf")
for e in range(args.epochs):
    print(f"Epoch {e} lr {optimizer.param_groups[0]['lr']}")
    train_fn = model.train_ie_epoch if not args.vie else model.train_vie_epoch
    validate_fn = model.validate_ie if not args.vie else model.validate_vie

    # Train
    #train_loss, tntok, tp, fp, fn, tm, tg = train_fn(
    train_loss, tntok = train_fn(
        iter      = train_iter,
        clip      = args.clip,
        re        = args.re,
        optimizer = optimizer,
        supattn   = args.supattn,
        supcopy   = args.supcopy,
        T         = args.T,
        E         = args.E,
        R         = args.R,
    )

    # Validate
    #valid_loss, ntok, tp, fp, fn, tm, tg = validate_fn(valid_iter, T=args.T, E=args.E)
    valid_loss, ntok = validate_fn(valid_iter, T=args.T, E=args.E)
    print(f"Epoch {e} train loss: {train_loss / tntok} valid loss: {valid_loss / ntok}")
    schedule.step(valid_loss / ntok)

    if args.save and valid_loss < best_val:
        best_val = valid_loss
        savestring = f"{modelname}/{modelname}-e{e}.pt"
        torch.save({"model": model.state_dict(), "args": args}, savestring)
